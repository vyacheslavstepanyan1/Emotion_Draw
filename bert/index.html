
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../data/">
      
      
        <link rel="next" href="../model/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.19">
    
    
      
        <title>BERT - Emotion Draw ðŸŽ¨</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.66ac8b77.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#emotion-draw-with-albert-the-mighty-mite" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Emotion Draw ðŸŽ¨" class="md-header__button md-logo" aria-label="Emotion Draw ðŸŽ¨" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Emotion Draw ðŸŽ¨
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              BERT
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="lime"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href=".." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../user_guide/" class="md-tabs__link">
        
  
    
  
  User Guide

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../data/" class="md-tabs__link">
        
  
    
  
  Dataset

      </a>
    </li>
  

      
        
  
  
    
  
  
    <li class="md-tabs__item md-tabs__item--active">
      <a href="./" class="md-tabs__link">
        
  
    
  
  BERT

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../model/" class="md-tabs__link">
        
  
    
  
  MulticlassClassificationTrainer()

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../step_by_step/" class="md-tabs__link">
        
  
    
  
  Step-by-Step

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../diffusion/" class="md-tabs__link">
        
  
    
  
  Stable Diffusion

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../fast_api/" class="md-tabs__link">
        
  
    
  
  FastAPI Integration

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../js/" class="md-tabs__link">
        
  
    
  
  JS React Integration

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Emotion Draw ðŸŽ¨" class="md-nav__button md-logo" aria-label="Emotion Draw ðŸŽ¨" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Emotion Draw ðŸŽ¨
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../user_guide/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    User Guide
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dataset
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    BERT
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    BERT
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#bert-the-big-the-bold-and-the-brainy-why-we-gave-it-a-pass" class="md-nav__link">
    <span class="md-ellipsis">
      BERT: The Big, the Bold, and the Brainy - Why We Gave It a Pass! ðŸ«£
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BERT: The Big, the Bold, and the Brainy - Why We Gave It a Pass! ðŸ«£">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#albert-the-chosen-one" class="md-nav__link">
    <span class="md-ellipsis">
      ALBERT: The Chosen One! ðŸš€
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ALBERT: The Chosen One! ðŸš€">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#overview_1" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pre-training-tasks" class="md-nav__link">
    <span class="md-ellipsis">
      Pre-training Tasks
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#advantages-for-classification-tasks" class="md-nav__link">
    <span class="md-ellipsis">
      Advantages for Classification Tasks
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#experiment-findings-alberts-performance" class="md-nav__link">
    <span class="md-ellipsis">
      Experiment Findings: ALBERT's Performance ðŸ’¡
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-do-the-others-perform" class="md-nav__link">
    <span class="md-ellipsis">
      How Do the Others Perform?
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../model/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MulticlassClassificationTrainer()
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../step_by_step/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Step-by-Step
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../diffusion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Stable Diffusion
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../fast_api/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FastAPI Integration
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../js/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    JS React Integration
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="emotion-draw-with-albert-the-mighty-mite"><strong>ðŸŽ¨ Emotion Draw with ALBERT: The Mighty Mite! ðŸ¤–</strong></h1>
<h2 id="bert-the-big-the-bold-and-the-brainy-why-we-gave-it-a-pass"><strong><a href="https://huggingface.co/docs/transformers/en/model_doc/bert">BERT:</a> The Big, the Bold, and the Brainy - Why We Gave It a Pass! ðŸ«£</strong></h2>
<p>BERT, short for Bidirectional Encoder Representations from Transformers, is a transformer-based, pre-trained natural language processing (NLP) model introduced by Google in 2018. It was proposed in <a href="https://arxiv.org/abs/1810.04805">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a> by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova. It utilizes a bidirectional Transformer architecture, effectively capturing context from both left and right directions in a given text sequence. It revolutionized natural language processing (NLP) by introducing a pre-trained model on a large corpus comprising the Toronto Book Corpus and Wikipedia, that can be used in Transfer Learning for a wide range of downstream tasks.</p>
<p><img alt="BERT" src="../img/bert.webp" /></p>
<h3 id="overview"><strong>Overview</strong></h3>
<p>ðŸ“Œ <strong>Architecture</strong>: BERT is based on the transformer architecture, specifically the encoder part.</p>
<p>ðŸ“Œ <strong>Bidirectional Context</strong>: BERT leverages bidirectional context understanding by masking some of the input tokens and predicting them based on the surrounding context.</p>
<p>ðŸ“Œ <strong>Pre-training</strong>: BERT is pre-trained on large corpora of text data using two unsupervised tasks: masked language modeling and next sentence prediction.</p>
<p><strong>Note:</strong> Refer to <a href="https://huggingface.co/docs/transformers/en/model_doc/bert#transformers.BertForSequenceClassification">transformers.BertForSequenceClassification</a> for technical documentation.</p>
<h2 id="albert-the-chosen-one"><strong><a href="https://huggingface.co/docs/transformers/en/model_doc/albert">ALBERT:</a> The Chosen One! ðŸš€</strong></h2>
<p><img alt="ALBERT" src="../img/albert.jpeg" /></p>
<p>ALBERT, short for A Lite BERT, is a variant of the BERT (Bidirectional Encoder Representations from Transformers) model developed by Google AI's researchers, and proposed in <a href="https://arxiv.org/abs/1909.11942">ALBERT: A Lite BERT for Self-supervised Learning of Language Representations</a> by Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut. It is designed to address some of the limitations of the original BERT model, such as its large size and computational cost, while maintaining or even improving performance on various natural language processing (NLP) tasks.</p>
<h3 id="overview_1"><strong>Overview</strong></h3>
<ul>
<li>
<p><strong>Parameter Reduction</strong>: ALBERT introduces several parameter reduction techniques such as splitting the embedding matrix into two smaller matrices and using repeating layers split among groups to reduce the number of model parameters while maintaining performance. </p>
</li>
<li>
<p><strong>Efficient Pre-training</strong>: ALBERT is pre-trained using unsupervised learning objectives similar to BERT, such as masked language modeling and next sentence prediction.</p>
</li>
<li>
<p><strong>Transformer Architecture</strong>: Like BERT, ALBERT is based on the transformer architecture, which enables it to capture bidirectional context understanding in text data.</p>
</li>
</ul>
<h3 id="pre-training-tasks"><strong>Pre-training Tasks</strong></h3>
<p>ALBERT is pre-trained using the following unsupervised learning tasks:</p>
<ol>
<li>
<p><strong>Masked Language Modeling (MLM)</strong>: Similar to BERT, ALBERT randomly masks some of the input tokens and predicts them based on the surrounding context. This task encourages the model to learn robust representations of words and phrases.</p>
</li>
<li>
<p><strong>Sentence Order Prediction (SOP)</strong>: ALBERT also utilizes a sentence order prediction task, where it learns to predict whether two input sentences appear consecutively in the original text or are randomly shuffled. This task helps the model capture relationships between sentences and improve its understanding of document-level context.</p>
</li>
</ol>
<h3 id="advantages-for-classification-tasks"><strong>Advantages for Classification Tasks</strong></h3>
<p>ALBERT offers several advantages for classification tasks:</p>
<ul>
<li>
<p><strong>Parameter Efficiency</strong>: ALBERT achieves a significant reduction in the number of model parameters compared to BERT. This reduction in parameters leads to improved parameter efficiency, making ALBERT more suitable for deployment in resource-constrained environments.</p>
</li>
<li>
<p><strong>Faster Training</strong>: Due to its reduced parameter count, ALBERT typically trains faster than BERT, resulting in shorter training times and reduced computational costs.</p>
</li>
<li>
<p><strong>Performance Retention</strong>: Despite its parameter reduction, ALBERT aims to retain or even improve performance compared to BERT on various NLP tasks. This makes it an attractive choice for classification tasks where both performance and efficiency are crucial considerations.</p>
</li>
</ul>
<p><strong>Note:</strong> Refer to <a href="https://huggingface.co/docs/transformers/v4.40.1/en/model_doc/albert#transformers.AlbertForSequenceClassification">transformers.AlbertForSequenceClassification</a> for technical documentation.</p>
<h3 id="experiment-findings-alberts-performance"><strong>Experiment Findings: ALBERT's Performance ðŸ’¡</strong></h3>
<table>
<thead>
<tr>
<th>Experiment No.</th>
<th>Model</th>
<th>Checkpoint Saved From</th>
<th>Checkpoint File</th>
<th>Accuracy (%)</th>
<th>F1 Score (%)</th>
<th>Avg Loss</th>
<th>Learning Rate</th>
<th>Batch Size</th>
<th>Training Epochs</th>
<th>Data Portion Used (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>albert-base-v2</td>
<td>Epoch 20</td>
<td>multiclass_experiment1_albert-base-v2_epoch20_checkpoint.pth</td>
<td>79.80</td>
<td>72.44</td>
<td>0.74</td>
<td>1e-5</td>
<td>32</td>
<td>20</td>
<td>10</td>
</tr>
<tr>
<td>1</td>
<td>albert-base-v2</td>
<td>The epoch with the lowest validation loss</td>
<td>multiclass_experiment1_albert-base-v2_best_checkpoint.pth</td>
<td>79.75</td>
<td>71.98</td>
<td>0.7</td>
<td>1e-5</td>
<td>32</td>
<td>20</td>
<td>10</td>
</tr>
<tr>
<td>2</td>
<td>albert-base-v2</td>
<td>Epoch 20</td>
<td>multiclass_experiment2_albert-base-v2_epoch20_checkpoint.pth</td>
<td>92.10</td>
<td>88.31</td>
<td>0.27</td>
<td>1e-5</td>
<td>32</td>
<td>20</td>
<td>100</td>
</tr>
<tr>
<td>2</td>
<td>albert-base-v2</td>
<td>The epoch with the lowest validation loss</td>
<td>multiclass_experiment2_albert-base-v2_best_checkpoint.pth</td>
<td>91.95</td>
<td>87.63</td>
<td>0.17</td>
<td>1e-5</td>
<td>32</td>
<td>20</td>
<td>100</td>
</tr>
<tr>
<td>3</td>
<td>albert-base-v2</td>
<td>Epoch 20</td>
<td>multiclass_experiment3_albert-base-v2_epoch20_checkpoint.pth</td>
<td>92.20</td>
<td>88.36</td>
<td>0.26</td>
<td>2e-5</td>
<td>64</td>
<td>20</td>
<td>100</td>
</tr>
<tr>
<td>3</td>
<td>albert-base-v2</td>
<td>The epoch with the lowest validation loss</td>
<td>multiclass_experiment3_albert-base-v2_best_checkpoint.pth</td>
<td>93.25</td>
<td>89.27</td>
<td>0.14</td>
<td>2e-5</td>
<td>64</td>
<td>20</td>
<td>100</td>
</tr>
</tbody>
</table>
<h2 id="how-do-the-others-perform"><strong>How Do the Others Perform?</strong></h2>
<p>If you are interested in the performance of the other BERT-based models on the <a href="https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp?resource=download">Emotions Dataset for NLP</a>, you can refer to these sources.</p>
<p>ðŸ“Œ <a href="https://medium.com/@kefactor/benchmarking-bert-based-models-for-text-classification-7182db4df89a">Benchmarking BERT-based models for text classification.</a></p>
<p>ðŸ“Œ <a href="https://huggingface.co/bhadresh-savani/bert-base-uncased-emotion#model-performance-comparision-on-emotion-dataset-from-twitter">Model Performance Comparision on Emotion Dataset from Twitter</a></p>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var tab,labels=set.querySelector(".tabbed-labels");for(tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.tabs", "navigation.sections", "toc.integrate", "navigation.top", "search.suggest", "search.highlight", "content.tabs.link", "content.code.annotation", "content.code.copy"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.dd8806f2.min.js"></script>
      
    
  </body>
</html>